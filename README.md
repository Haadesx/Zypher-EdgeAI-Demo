# Zypher EdgeAI Demo ğŸš€
> **Real-time Gesture Recognition on Arm Cortex-M3 with TensorFlow Lite Micro & Zephyr RTOS**

<p align="center">
  <img src="docs/images/architecture_diagram.svg" alt="Architecture Diagram" width="600">
</p>

[![CI Status](https://github.com/Haadesx/Zypher-EdgeAI-Demo/actions/workflows/build.yml/badge.svg)](https://github.com/Haadesx/Zypher-EdgeAI-Demo/actions)
[![Developer](https://img.shields.io/badge/Developer-Varesh%20Patel-0052CC)](https://github.com/Haadesx)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Zephyr RTOS](https://img.shields.io/badge/Zephyr-3.7.0-blue)](https://zephyrproject.org/)
[![TensorFlow Lite](https://img.shields.io/badge/TFLite-Micro-orange)](https://www.tensorflow.org/lite/microcontrollers)

> A production-quality embedded AI application demonstrating real-time gesture recognition on ARM Cortex-M using Zephyr RTOS and TensorFlow Lite Micro.

## âœ¨ Features

- **ğŸ¯ Real-Time Gesture Recognition**: Detects 4 gesture classes (IDLE, WAVE, TAP, CIRCLE) using accelerometer data
- **ğŸ§  TensorFlow Lite Micro**: Quantized INT8 model with CMSIS-NN optimizations for ARM
- **âš™ï¸ Production-Ready Architecture**: Multi-threaded design with proper RTOS primitives
- **ğŸ” Comprehensive Debug Infrastructure**: Stack monitoring, heap tracking, and documented bug fixes
- **ğŸ’» Zero Hardware Required**: Runs entirely on QEMU with mock sensor data
- **ğŸ“Š Python Analysis Tools**: UART logger, latency analyzer, and automated test harness
- **ğŸ”„ CI/CD Ready**: GitHub Actions workflow for automated builds

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sensor Thread  â”‚â”€â”€â”€â”€â–¶â”‚  Preprocessing  â”‚â”€â”€â”€â”€â–¶â”‚   ML Thread     â”‚
â”‚    (100 Hz)     â”‚     â”‚  Window Buffer  â”‚     â”‚   (on demand)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                        â”‚  Debug Monitor  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                        â”‚    (1 Hz)       â”‚              â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â–¼
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚  UART Output    â”‚
                                                â”‚  (JSON format)  â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Component | Description |
|-----------|-------------|
| **Sensor Thread** | Samples accelerometer at 100Hz, feeds preprocessing |
| **Preprocessing** | Sliding window accumulation, INT8 quantization |
| **ML Thread** | TFLite-Micro inference with CMSIS-NN kernels |
| **Debug Monitor** | Stack/heap monitoring, health checks |
| **UART Output** | JSON-formatted results for analysis |

## ğŸš€ Quick Start

### Prerequisites

- **macOS/Linux**: Recommended for development
- **Python 3.8+**: For build tools and analysis scripts
- **Zephyr SDK**: Will be installed via west

### One-Line Setup

```bash
# Clone and setup
git clone https://github.com/Haadesx/Zypher-EdgeAI-Demo.git
cd Zypher-EdgeAI-Demo
./scripts/setup.sh  # Installs Zephyr SDK and dependencies
```

### Manual Setup

See [GETTING_STARTED.md](GETTING_STARTED.md) for detailed instructions.

```bash
# 1. Create Python virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 2. Install west
pip install west

# 3. Initialize workspace
west init -l .
west update

# 4. Install Zephyr SDK
west sdk install

# 5. Build for QEMU (ARM Cortex-M3)
west build -b mps2/an385 -p always

# 6. Run in QEMU
west build -t run
```

### Expected Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     Zephyr Edge AI Demo - Gesture Recognition           â•‘
â•‘     Version: 1.0.0                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{"type":"startup","version":"1.0.0","board":"mps2/an385","ts":1234}
[00:00:03.123] Starting gesture: WAVE
{"type":"inference","seq":1,"ts":3456789,"gesture":"WAVE","conf":0.94,"latency_us":12340}
{"type":"debug","ts":4000000,"heap_used":1024,"stack_used":2800}
```

## ğŸ“Š Analysis Tools

### Collect UART Logs

```bash
# From real hardware
python scripts/uart_logger.py --port /dev/ttyACM0 --output results.csv

# Simulation mode (paste QEMU output)
python scripts/uart_logger.py --simulate
```

### Analyze Latency

```bash
python scripts/latency_analyzer.py --input results.csv --output report.png
```

**Sample Output:**
```
INFERENCE LATENCY ANALYSIS REPORT
================================================
## Overall Latency Statistics (Âµs)
  Count:     1,234
  Minimum:   8,500
  Maximum:   15,200
  Average:   11,340.5
  P95:       13,800
  P99:       14,500

## Latency by Gesture (Âµs)
  Gesture       Count        Avg        P50        P95
  ------------------------------------------------
  IDLE            450    10,200     10,100     11,500
  WAVE            280    12,100     11,900     13,200
  TAP             254    11,800     11,600     13,000
  CIRCLE          250    11,900     11,700     13,100
```

## ğŸ”§ Configuration

Key configuration options in `prj.conf`:

| Option | Default | Description |
|--------|---------|-------------|
| `CONFIG_SENSOR_SAMPLE_RATE_HZ` | 100 | Accelerometer sampling rate |
| `CONFIG_ML_TENSOR_ARENA_SIZE` | 8192 | TFLite memory arena (bytes) |
| `CONFIG_ML_INFERENCE_WINDOW_SIZE` | 50 | Samples per inference |
| `CONFIG_ML_CONFIDENCE_THRESHOLD` | 70 | Min confidence for detection |

See [Kconfig](Kconfig) for all options.

## ğŸ› Debugging Story

This project includes a documented investigation of a real issue encountered during development:

### Stack Overflow in ML Thread

**Symptom**: Application crashed during first inference attempt.

**Investigation**:
1. Enabled `CONFIG_STACK_SENTINEL=y` to detect stack corruption
2. Added stack monitoring via `k_thread_stack_space_get()`
3. Observed ML thread stack at 98% usage with 1KB allocation

**Root Cause**: TFLite-Micro's interpreter uses ~2.5KB of stack space for tensor operations.

**Fix**: Increased `ML_STACK_SIZE` from 1024 to 4096 bytes.

**Validation**: Added runtime monitoring showing peak usage of ~2.8KB (70% of new allocation).

See [DEBUGGING.md](docs/DEBUGGING.md) for the complete investigation walkthrough.

## ğŸ“ Project Structure

```
zephyr-edge-ai-demo/
â”œâ”€â”€ CMakeLists.txt          # Build configuration
â”œâ”€â”€ prj.conf                # Zephyr Kconfig settings
â”œâ”€â”€ west.yml                # West manifest
â”œâ”€â”€ Kconfig                 # Custom config options
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.c              # Application entry
â”‚   â”œâ”€â”€ sensor/             # Sensor HAL + mock
â”‚   â”œâ”€â”€ ml/                 # TFLite-Micro inference
â”‚   â”œâ”€â”€ output/             # UART protocol
â”‚   â””â”€â”€ debug/              # Monitoring infrastructure
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ uart_logger.py      # Log collection
â”‚   â”œâ”€â”€ latency_analyzer.py # Performance analysis
â”‚   â””â”€â”€ test_harness.py     # Automated testing
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # System design
â”‚   â””â”€â”€ DEBUGGING.md        # Bug investigation
â”‚
â””â”€â”€ .github/workflows/      # CI/CD
```

## ğŸ¯ Target Platforms

| Board | Status | Notes |
|-------|--------|-------|
| **mps2/an385** (QEMU) | âœ… Tested | Default target, no hardware needed |
| STM32F4 Discovery | ğŸ”„ Planned | Real accelerometer support |
| nRF52840 DK | ğŸ”„ Planned | BLE output option |

## ğŸ“ˆ Performance

Measured on QEMU (emulated ARM Cortex-M3):

| Metric | Value |
|--------|-------|
| Inference Latency (avg) | ~12ms |
| Inference Latency (P95) | ~14ms |
| Model Size | ~10KB |
| RAM Usage (heap) | ~2KB |
| Stack Usage (ML thread) | ~2.8KB |
| Flash Usage (total) | ~80KB |

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run the test harness: `python scripts/test_harness.py`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- [Zephyr Project](https://zephyrproject.org/) for the excellent RTOS
- [TensorFlow Lite Micro](https://www.tensorflow.org/lite/microcontrollers) for embedded ML
- [ARM CMSIS-NN](https://arm-software.github.io/CMSIS_5/NN/html/index.html) for optimized kernels

---

<p align="center">
  <b>Designed & Developed by <a href="https://github.com/Haadesx">Varesh Patel</a></b><br>
</p>
